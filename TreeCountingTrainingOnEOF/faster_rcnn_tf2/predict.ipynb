{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458421aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 12:23:25.370082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# from pyexpat import model\n",
    "import numpy as np\n",
    "from tqdm import *\n",
    "import cv2\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from mrcnn.config import Config\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.strtree import STRtree\n",
    "from utils.utils import transform_poly_px_to_geom, convert_window_to_polygon\n",
    "import tensorflow as tf\n",
    "from get_image_resolution_meter import get_resolution_meter\n",
    "MODEL_SIZE = 512\n",
    "MODEL_DIR=\"\"\n",
    "NUM_BAND=3\n",
    "NMS_TH=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d37fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(Config):\n",
    "    \"\"\"Config for predict tree counting model\"\"\"\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1  # 1 Background + 1 Building\n",
    "    IMAGE_MAX_DIM = MODEL_SIZE + 64\n",
    "    IMAGE_MIN_DIM = MODEL_SIZE + 64\n",
    "    DETECTION_MAX_INSTANCES = 200\n",
    "    MAX_GT_INSTANCES = 20\n",
    "\n",
    "    MASK_SHAPE = [28, 28]\n",
    "\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)\n",
    "\n",
    "    NAME = \"tree_counting_model\"\n",
    "\n",
    "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n",
    "    # RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "\n",
    "    DETECTION_NMS_THRESHOLD = NMS_TH\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c2901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_by_window(dataset_image, x_off, y_off, x_count, y_count, start_x, start_y, input_size ):\n",
    "    \"\"\" \n",
    "    This function to read image window by coordinates\n",
    "    \"\"\"\n",
    "    num_band = NUM_BAND\n",
    "\n",
    "    image_detect = dataset_image.read(window=Window(x_off, y_off, x_count, y_count))[0:num_band].swapaxes(0, 1).swapaxes(1,\n",
    "                                                                                                                     2)\n",
    "    if image_detect.shape[0] < input_size or image_detect.shape[1] < input_size:\n",
    "        img_temp = np.zeros((input_size, input_size, image_detect.shape[2]))\n",
    "        if start_x == 0 and start_y == 0:\n",
    "            img_temp[(input_size - image_detect.shape[0]):input_size, (input_size - image_detect.shape[1]):input_size] = image_detect\n",
    "        elif start_x == 0:\n",
    "            img_temp[0:image_detect.shape[0], (input_size - image_detect.shape[1]):input_size] = image_detect\n",
    "        elif start_y == 0:\n",
    "            img_temp[(input_size - image_detect.shape[0]):input_size, 0:image_detect.shape[1]] = image_detect\n",
    "        else:\n",
    "            img_temp[0:image_detect.shape[0], 0:image_detect.shape[1]] = image_detect\n",
    "        image_detect = img_temp\n",
    "    return image_detect.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39d08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_list_slide_windows(h, w, input_size, stride_size):\n",
    "    \"\"\" \n",
    "    This function to gen all window coordinates for predict big image\n",
    "    \"\"\"\n",
    "    list_coordinates = []\n",
    "    padding = int((input_size - stride_size) / 2)\n",
    "    new_w = w + 2 * padding\n",
    "    new_h = h + 2 * padding\n",
    "    cut_w = list(range(padding, new_w - padding, stride_size))\n",
    "    cut_h = list(range(padding, new_h - padding, stride_size))\n",
    "    list_height = []\n",
    "    list_weight = []\n",
    "    # print(w, h)\n",
    "    for i in cut_h:\n",
    "        list_height.append(i)\n",
    "\n",
    "    for i in cut_w:\n",
    "        list_weight.append(i)\n",
    "    for i in range(len(list_height)):\n",
    "        top_left_y = list_height[i]\n",
    "        for j in range(len(list_weight)):\n",
    "            top_left_x = list_weight[j]\n",
    "            start_x = top_left_x - padding\n",
    "            end_x = min(top_left_x + stride_size + padding, new_w - padding)\n",
    "            start_y = top_left_y - padding\n",
    "            end_y = min(top_left_y + stride_size + padding, new_h - padding)\n",
    "            if start_x == 0:\n",
    "                x_off = start_x\n",
    "            else:\n",
    "                x_off = start_x - padding\n",
    "            if start_y == 0:\n",
    "                y_off = start_y\n",
    "            else:\n",
    "                y_off = start_y - padding\n",
    "            x_count = end_x - padding - x_off\n",
    "            y_count = end_y - padding - y_off\n",
    "            list_coordinates.append(tuple([x_off, y_off, x_count, y_count, start_x, start_y]))\n",
    "    return list_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c48074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_small_image(dataset_image, model_path,resolution):\n",
    "    \"\"\"\n",
    "        predict for image small than model input size\n",
    "    \"\"\"\n",
    "    num_band = NUM_BAND\n",
    "    from mrcnn import model as modellib\n",
    "    w, h = dataset_image.width, dataset_image.height\n",
    "    image = dataset_image.read()[0:num_band].swapaxes(0, 1).swapaxes(1, 2).astype(np.uint8)\n",
    "    image_res = resolution\n",
    "    config = InferenceConfig()\n",
    "    config.IMAGE_MAX_DIM = (round(max(h, w) / 64 * 3.2 / 3 * image_res / 0.3)) * 64\n",
    "    config.IMAGE_MIN_DIM = (round(min(h, w) / 64 * 3.2 / 3 * image_res / 0.3)) * 64\n",
    "    config.display()\n",
    "\n",
    "    model = modellib.MaskRCNN(\n",
    "        mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "    print(\"inside predict api\")\n",
    "    print(model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "    predictions = model.detect([image] * config.BATCH_SIZE, verbose=1)\n",
    "    p = predictions[0]\n",
    "    boxes = p['rois']\n",
    "    scores = p['scores']\n",
    "    N = boxes.shape[0]\n",
    "    list_contours = []\n",
    "    list_score = []\n",
    "    for i in range(N):\n",
    "        if not np.any(boxes[i]):\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        contour = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2], [x1, y1]])\n",
    "        contour = contour.reshape(-1, 1, 2)\n",
    "        try:\n",
    "            if cv2.contourArea(contour) > 100:\n",
    "                list_contours.append(contour)\n",
    "                list_score.append(scores[i])\n",
    "        except Exception:\n",
    "            pass\n",
    "    predictions = None\n",
    "    p = None\n",
    "    model = None\n",
    "    return list_contours, list_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ab8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_big_image(dataset_image, model_path, resolution, bound_aoi, out_type, verbose):\n",
    "    \"\"\"\n",
    "    Function to predict big image with stride window.\n",
    "\n",
    "    dataset_image: dataset open by rasterio\n",
    "    model_path: Mask-RCNN h5 weight\n",
    "    num_band: num channel config for image\n",
    "    input_size: input size image to push to model\n",
    "    stride_size: stride window size\n",
    "    bound_aoi: shapely polygon area AIO care in this image predict\n",
    "    \"\"\"\n",
    "    from mrcnn import model as modellib\n",
    "    # get transform and image hw for calculator\n",
    "    w, h = dataset_image.width, dataset_image.height\n",
    "    transform = dataset_image.transform\n",
    "    # config model predict\n",
    "    config = InferenceConfig()\n",
    "    # config.display()\n",
    "    input_size = round(0.3*512/(resolution*64))*64\n",
    "    overlap_size = round(input_size*2/10)*2\n",
    "    stride_size = input_size - overlap_size\n",
    "    # padding size for each stride window\n",
    "    padding = int((input_size - stride_size) / 2)\n",
    "    # call model\n",
    "    model = modellib.MaskRCNN(\n",
    "        mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "    # load weight\n",
    "    if verbose:\n",
    "        print(\"Loaded model\")\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "    # create list for save result when predict\n",
    "    return_contour = []\n",
    "    return_score = []\n",
    "    # Calculator all window location before predict\n",
    "    list_window_coordinates = gen_list_slide_windows(h, w, input_size, stride_size)\n",
    "    if verbose:\n",
    "        print(\"Predicting ...\")\n",
    "    with tqdm(total=len(list_window_coordinates), disable = not(verbose)) as p_bar:\n",
    "        for window_coordinate in list_window_coordinates:\n",
    "            # get each coordinates in list window coordinates\n",
    "            x_off, y_off, x_count, y_count, start_x, start_y = window_coordinate\n",
    "            # get image window by coordinate\n",
    "            image_detect = read_image_by_window(dataset_image, x_off, y_off, x_count, y_count, start_x, start_y,input_size)\n",
    "\n",
    "            # calculator bound polygon of window for check intersect with AOI care\n",
    "            polygon_bound = convert_window_to_polygon(x_off, y_off, x_count, y_count)\n",
    "            geo_polygon = Polygon(transform_poly_px_to_geom(polygon_bound, transform))\n",
    "            check_inter = geo_polygon.intersects(bound_aoi)\n",
    "            # if image not no data and intersect with AIO care then push to predict\n",
    "            if np.count_nonzero(image_detect) > 0 and check_inter:\n",
    "                predictions = model.detect([image_detect] * config.BATCH_SIZE, verbose=0)\n",
    "                p = predictions[0]\n",
    "                ##########################################################\n",
    "                # get box and  score and convert box to opencv contour fomat\n",
    "                boxes = p['rois']\n",
    "                N = boxes.shape[0]\n",
    "                list_temp = []\n",
    "                list_score_temp = []\n",
    "                for i in range(N):\n",
    "                    if not np.any(boxes[i]):\n",
    "                        continue\n",
    "                    y1, x1, y2, x2 = boxes[i]\n",
    "                    score = p[\"scores\"][i]\n",
    "                    if out_type==\"bbox\":\n",
    "                        contour = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2], [x1, y1]])\n",
    "                        contour = contour.reshape(-1, 1, 2)\n",
    "                    else:\n",
    "                        true_mask_result = p['masks'][:, :, i].astype(np.uint8)\n",
    "                        im2, contours, hierarchy = cv2.findContours(true_mask_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        if len(contours)>0:\n",
    "                            contour = contours[0]\n",
    "                            _, radius_f = cv2.minEnclosingCircle(contour)\n",
    "                            for cnt in contours:\n",
    "                                _, radius = cv2.minEnclosingCircle(cnt)\n",
    "                                if radius>radius_f:\n",
    "                                    radius_f = radius\n",
    "                                    contour = cnt\n",
    "                    try:\n",
    "                        if cv2.contourArea(contour) > 10:\n",
    "                            if (contour.max() < (input_size - padding)) and (contour.min() > padding):\n",
    "                                # print(1)\n",
    "                                list_temp.append(contour)\n",
    "                                list_score_temp.append(score)\n",
    "                            elif (contour.max() < (input_size - 5)) and (contour.min() > 5):\n",
    "                                list_temp.append(contour)\n",
    "                                list_score_temp.append(score)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                #########################################################\n",
    "                # change polygon from window image predict coords to big image coords\n",
    "                temp_contour = []\n",
    "                for contour in list_temp:\n",
    "                    tmp_poly_window = contour.reshape(-1, 2)\n",
    "                    tmp_poly = tmp_poly_window + np.array([start_x - padding, start_y - padding])\n",
    "                    con_rs = tmp_poly.reshape(-1, 1, 2)\n",
    "                    temp_contour.append(con_rs)\n",
    "                return_contour.extend(temp_contour)\n",
    "                return_score.extend(list_score_temp)\n",
    "            p_bar.update()\n",
    "            # FOR LOOP ALL WINDOW\n",
    "    predictions = None\n",
    "    p = None\n",
    "    model = None\n",
    "    list_contours = return_contour\n",
    "    list_scores = return_score\n",
    "    return list_contours, list_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5a4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bound(image_path, bound_path, id_image):\n",
    "    \"\"\"get Aoi bound from AOI care, if none, return image bound\"\"\"\n",
    "    with rasterio.open(image_path) as src:\n",
    "        transform = src.transform\n",
    "        w, h = src.width, src.height\n",
    "        proj_str = (src.crs.to_string())\n",
    "    bound_image = ((0, 0), (w, 0), (w, h), (0, h), (0, 0))\n",
    "    try:\n",
    "        petak_id = id_image.split('_')[-2]\n",
    "    except:\n",
    "        petak_id = \"\"\n",
    "    if bound_path:\n",
    "        bound_shp = gp.read_file(bound_path)\n",
    "        bound_shp = bound_shp.to_crs(proj_str)\n",
    "        bound_aoi_table = bound_shp.loc[bound_shp[FIELDS_NAME] == petak_id]\n",
    "        # If have AOI go to predict\n",
    "        if len(bound_aoi_table) > 0:\n",
    "            # get AIO geometry\n",
    "            bound_aoi = bound_aoi_table.iloc[0].geometry\n",
    "            bound_aoi = bound_aoi.buffer(-1)\n",
    "        else:\n",
    "            bound_aoi = Polygon(transform_poly_px_to_geom(bound_image, transform))\n",
    "    else:\n",
    "        # if don't have bound aoi then predict all image\n",
    "        bound_aoi = Polygon(transform_poly_px_to_geom(bound_image, transform))\n",
    "    return bound_aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93aa72dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_predict_result_to_file(polygon_result_all, score_result_all, bound_aoi, transform, proj_str, out_format, image_id, output_path):\n",
    "    \"\"\"Export result to shapefile.\n",
    "    polygon_result_all: list polygon result after predict\n",
    "    score_result_all: score for each polygon\n",
    "    transform: transform get from image by rasterio\n",
    "    projstr: project string get from image by rasterio\n",
    "    output_shape_file : path to output shape file\n",
    "    \"\"\"\n",
    "\n",
    "    list_geo_polygon = [Polygon(transform_poly_px_to_geom(polygon, transform)) for polygon in polygon_result_all]\n",
    "    tree_polygon = [geom for geom in list_geo_polygon]\n",
    "    tree_point = [geom.centroid for geom in list_geo_polygon]\n",
    "    strtree_point = STRtree(tree_point)\n",
    "    index_by_id = dict((id(pt), i) for i, pt in enumerate(tree_point))\n",
    "\n",
    "    list_point = strtree_point.query(bound_aoi)\n",
    "    list_point_inside = [x for x in list_point if bound_aoi.contains(x)]\n",
    "\n",
    "    index_point = [index_by_id[id(pt)] for pt in list_point_inside]\n",
    "    tree_polygon_rs = [tree_polygon[index] for index in index_point]\n",
    "    tree_score_rs = [score_result_all[index] for index in index_point]\n",
    "    tree_id = list(range(len(tree_score_rs)))\n",
    "    data_tree = list(zip(tree_polygon_rs, tree_score_rs, tree_id))\n",
    "\n",
    "    df_polygon = pd.DataFrame(data_tree, columns=['geometry', 'score',\"FID\"])\n",
    "    gdf_polygon = gp.GeoDataFrame(df_polygon, geometry='geometry', crs=proj_str)\n",
    "\n",
    "\n",
    "    if out_format == \"shp\":\n",
    "        gdf_polygon.to_file(output_path)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32a22b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_result(list_polygons, list_scores, list_labels, iou_threshold=0.3):\n",
    "    list_shapely_polygons = [Polygon(polygon) for polygon in list_polygons]\n",
    "    list_bound = [np.array(polygon.bounds) for polygon in list_shapely_polygons]\n",
    "    indexes = tf.image.non_max_suppression(np.array(list_bound), np.array(list_scores), len(list_scores),iou_threshold=iou_threshold)\n",
    "    result_polygons = [list_polygons[idx] for idx in indexes]\n",
    "    result_scores = [list_scores[idx] for idx in indexes]\n",
    "    result_labels = [list_labels[idx] for idx in indexes]\n",
    "    return result_polygons,result_scores,result_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1797bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_main(image_path, model_path, output_path, bound_path=None,out_type=\"bbox\",verbose=0):\n",
    "    \"\"\"Predict image and write result to shape file out put.\n",
    "    image_path: input image tiff file\n",
    "    model_path: h5 weight model Mask-RCNN\n",
    "    output_path: output shape file path\n",
    "    bound_path: Path to shape file contain AOI care.\n",
    "    \"\"\"\n",
    "    out_format =\"shp\"\n",
    "    resolution = get_resolution_meter(image_path)\n",
    "\n",
    "    # Open data set for predict step ( Read by Window)  \n",
    "    with rasterio.open(image_path) as dataset_image:\n",
    "        # Read image information\n",
    "        transform = dataset_image.transform\n",
    "        w, h = dataset_image.width, dataset_image.height\n",
    "        proj_str = (dataset_image.crs.to_string())\n",
    "        # Get id image\n",
    "        image_name = os.path.basename(image_path)\n",
    "        image_id = os.path.splitext(image_name)[0]\n",
    "        # Get AOI by image ID\n",
    "        bound_aoi = get_bound(image_path, bound_path, image_id)\n",
    "        # Config image model and stride size\n",
    "        input_size = round(0.3*512/(resolution*64))*64\n",
    "\n",
    "        if h <= input_size or w <= input_size:\n",
    "            # predict when image too small\n",
    "            list_contours, list_scores = predict_small_image(dataset_image, model_path,resolution)\n",
    "        else:\n",
    "            # predict when image bigger than model size\n",
    "            list_contours, list_scores = predict_big_image(dataset_image, model_path, resolution, bound_aoi, out_type, verbose)\n",
    "\n",
    "    # reformat polygon from contour opencv2 to polygon shape (:,2)\n",
    "    list_polygons = [list_contours[i].reshape(-1, 2) for i in range(len(list_contours))]\n",
    "    if verbose:\n",
    "        print(\"Start Non-Maximum Suppression Tree ...\")\n",
    "    polygon_result_nms, score_result_nms = nms_result(list_polygons, list_scores)\n",
    "    # export result\n",
    "    if verbose:\n",
    "        print(\"Exporting result ...\")\n",
    "    export_predict_result_to_file(polygon_result_nms, score_result_nms, bound_aoi, transform, proj_str, out_format, image_id, output_path)\n",
    "\n",
    "    return len(polygon_result_nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28d3fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"/media/skymap/Data/Building_master_data/data_result/logs2_new/master_model20220518T2015/mask_rcnn_master_model_0185.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "559f77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import model as modellib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "840ed1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce7d503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ProposalLayer.call of <mrcnn.model.ProposalLayer object at 0x7f3d3cb47e50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method ProposalLayer.call of <mrcnn.model.ProposalLayer object at 0x7f3d3cb47e50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method PyramidROIAlign.call of <mrcnn.model.PyramidROIAlign object at 0x7f3d3cbe34c0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method PyramidROIAlign.call of <mrcnn.model.PyramidROIAlign object at 0x7f3d3cbe34c0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DetectionLayer.call of <mrcnn.model.DetectionLayer object at 0x7f3d3d827a60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DetectionLayer.call of <mrcnn.model.DetectionLayer object at 0x7f3d3d827a60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From /home/skymap/anaconda3/envs/farm_api38/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:AutoGraph could not transform <function refine_detections_graph.<locals>.nms_keep_map at 0x7f3d3ca2f790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function refine_detections_graph.<locals>.nms_keep_map at 0x7f3d3ca2f790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 12:23:33.880943: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-19 12:23:33.882844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-19 12:23:33.943646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-19 12:23:33.944812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.6575GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-05-19 12:23:33.944867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-19 12:23:33.947269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-19 12:23:33.947350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-05-19 12:23:33.949036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-19 12:23:33.949358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-19 12:23:33.951633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-19 12:23:33.952788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-19 12:23:33.957115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-05-19 12:23:33.957323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-19 12:23:33.958343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-19 12:23:33.959253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac4efa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 12:25:12.227494: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-19 12:25:12.232875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-19 12:25:12.234353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.6575GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-05-19 12:25:12.234551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-19 12:25:12.234683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-19 12:25:12.234779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-05-19 12:25:12.234886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-19 12:25:12.235000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-19 12:25:12.235098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-19 12:25:12.235197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-19 12:25:12.235315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-05-19 12:25:12.235535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-19 12:25:12.237068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-19 12:25:12.238354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-05-19 12:25:12.239522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-19 12:25:14.295936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-19 12:25:14.296162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-05-19 12:25:14.296182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-05-19 12:25:14.296737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-19 12:25:14.297795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-19 12:25:14.298796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-19 12:25:14.299699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10256 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0, compute capability: 6.1)\n",
      "2022-05-19 12:25:14.303080: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-19 12:25:14.810259: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2022-05-19 12:25:15.096178: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2663945000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 185\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6429e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
